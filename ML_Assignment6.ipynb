{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. In the sense of machine learning, what is a model? What is the best way to train a model?\n",
    "A machine learning Model can be seen as a function that maps input data to output data. It learns relationships between inputs and outputs. It predicts, classifies,  finds  inner relationships within the data.\n",
    "\n",
    "Best way to train the model depends on our target and type of model. We have  to preprocess the data, split data to train and test sets, and by choosing suitable algorithm,  we have to train the model by choosing right parameters, and measuring the performance by right metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In the sense of machine learning, explain the &quot;No Free Lunch&quot; theorem.\n",
    "No Free Lunch (NFL) theorem means : no algorithm works best than other algorithms for all problems.  This theorem suggests that we have to select the algorithm based on specific problem and by choosing right hyperparameters , we can select the Algorithm. Performance of algorithm depends on quality of data, complexity of the problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Describe the K-fold cross-validation mechanism in detail.\n",
    "\n",
    "Mainly we use k-fold validation for evaluating a modelâ€™s performance and hyperparameter tuning.\n",
    "\n",
    "In k fold validation , dataset is split into k folds. Then the model is trained with k-1 subsets and tested with remaining subset. It is repeated k times. The results from all these times are averaged to produce a single metreic for the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Describe the bootstrap sampling method. What is the aim of it?\n",
    "\n",
    "It is a method, that takes a sample of size \"n\" from the original data with replacement multiple times to create multiple boostrap samples. These samples then used to estimate the performance of the model. \n",
    "\n",
    "The aim of the bootstrap sampling is to reduce overfitting. It can lead to more accurate estimate of the model's performance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results.\n",
    "Kappa is commonly used to measure the performance of the classification models, it ranges from -1 to +1. It measures how well the model agrees with thew true labels.\n",
    "\n",
    "kappa = (observed agreement- expected agreement)/(1-expected agreement)\n",
    "\n",
    "observed agreement is the proportiojn of the cases where both lsbels agree and  the expected agreement is the proportion of the cases where is the expected by chance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Describe the model ensemble method. In machine learning, what part does it play?\n",
    "\n",
    "Ensemble model method is combining the multiple models to increase the accuracy.  BAGGING, BOOSTING, STACKING are the methods for model ensemble. It reduces the overfitting. It improves the accuracy of the model by combining multiple models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What is a descriptive model&#39;s main purpose? Give examples of real-world problems that descriptive models were used to solve.\n",
    "\n",
    "Descriptive mode3l is a type of the model that is use to summarise and describe the patterns and relationships in the data.  These are used for EDA, t ogain the insights. Clustering models, Association Rule models, Dimensionality Reuction, Anomaly detection models can be considered as descriptive models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Describe how to evaluate a linear regression model.\n",
    "\n",
    "We can use root mean sqaured error(RMSE) or Mean sqaured Error(MSE), R-Sqaured error, Mean Absolute error(MAE), Adjusted R-Squared error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models : descriptive models are use to find the relations and groups and associations in the data where as predictive models are used to predcit or classify the values.\n",
    "\n",
    "2. Underfitting vs. overfitting the model : overfitting occurs when the model is too cojmplex and captures noise in the data rather than the underlying patterns in the data. It is characterised by high variance that means models performs well in training by poorly performs in test set.  it occurs when the model has too many parameters or when training dataset is small. \n",
    "\n",
    "Underfittingg occurs when the model is too simple and fails to understand the underlying patterns and relationships. It is charactwrised by high bias, where model performs poorly both on training and test sets. It occurs when model has few parameters.\n",
    "\n",
    "3. Bootstrapping vs. cross-validation : Thse both are resampling techniques.  Bootstrap involves creating multiple samples with replacment from original dataset, with each sample has same number of features.With thse samples , it trains the models and measure the accuracy by averaging or mode of them. If dataset is highly imbalanced, it gives bias results. Cross validation involves splitting the dataset into mutiple subsets and each subset is used as validation set and remaining subsets as training sets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Make quick notes on:\n",
    "1. LOOCV - leave-one-out-cross-validation is a type of croos validation, divides dataset to n subsamples and use n-1 subsamples for training and one sample for testing. It is repeated n times. it is highly senstive to outliers. it is may not be appropriatew for dataset with large number of samples.\n",
    "\n",
    "2. F-measurement : It is widely used performance metric for classification problems. It is the harmonic mean of precision and recall.it ranges between 0 to 1. It is useful when dataset is imbalanced.\n",
    "\n",
    "3. The width of the silhouette : It is the measure of how well defined the clusters are in the clustering alhorithm. It ranges between -1 to 1. 1 represents clusters are well clustered. \n",
    "\n",
    "4. Receiver operating characteristic curve : ROC curve, is a graphical representation of a binary classification  model. IT is the plot between TPR and FPR. it is useful when dataset is imbalanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
